import sys
sys.path.insert(0, './yolov5')
# from ByteTrack.yolox.tracker.byte_tracker import BYTETracker
import myLib.get_PID_and_Kill
import supervision as sv
from yolov5.models.common import DetectMultiBackend
from yolov5.utils.downloads import attempt_download
from yolov5.utils.dataloaders import IMG_FORMATS, VID_FORMATS, LoadImages, LoadScreenshots, LoadStreams
from yolov5.utils.general import (LOGGER, Profile, check_file, check_img_size, check_imshow, check_requirements,
                                  colorstr, increment_path, non_max_suppression, print_args, scale_boxes,
                                  strip_optimizer)
from yolov5.utils.torch_utils import select_device, smart_inference_mode
from deep_sort_pytorch.utils.parser import get_config
from deep_sort_pytorch.deep_sort import DeepSort
from tools import ToolVehicle
from random import randint
import argparse,platform,time, datetime,re
from datetime import datetime, timedelta
from pathlib import Path
import cv2,os,torch,threading,pathlib
import torch.backends.cudnn as cudnn
# from torchvision.transforms import Equalize
import requests, json, base64
from requests.exceptions import RequestException
from flask import Flask, request, jsonify
import numpy as np
from random import randint
from deep_sort_pytorch.deep_sort import DeepSort
from datetime import datetime,timedelta,date
import subprocess
import AutoReCheckTime,RebootCheckTime
import shutil


# å…¨å±€è¿è¡Œçº¿ç¨‹æ§åˆ¶å˜é‡
current_run_thread = None
stop_run_flag = False


plt = platform.system()
if plt != "Windows":
    pathlib.WindowsPath = pathlib.PosixPath
import os

def exit_program():
    print("é€€å‡ºç¨‹åºï¼Œç»ˆæ­¢çº¿ç¨‹")
    os._exit(0)  # ç«‹å³å¼ºåˆ¶é€€å‡ºæ•´ä¸ªPythonç¨‹åºï¼ˆåŒ…æ‹¬æ‰€æœ‰çº¿ç¨‹ï¼‰




total_num = 0  # åˆå§‹åŒ–è½¦è¾†æ€»æ•°
RUN_SWITCH = False  # è¿è¡Œå¼€å…³ï¼Œç”¨äºæ§åˆ¶ä»»åŠ¡æ‰§è¡Œ
palette = (2 ** 11 - 1, 2 ** 15 - 1, 2 ** 20 - 1)  # è°ƒè‰²æ¿ï¼Œç”¨äºç»˜åˆ¶æ£€æµ‹æ¡†

# todo
# æ£€æµ‹çº¿çš„ä¸¤ä¸ªç«¯ç‚¹åæ ‡ï¼Œè¡¨ç¤ºè½¦è¾†ç»è¿‡æ—¶çš„æ£€æµ‹åŒºåŸŸ
# line = [500, 540, 1860, 540]  # æ£€æµ‹çº¿çš„ä¸¤ä¸ªç«¯ç‚¹çš„xyåæ ‡ï¼Œæ€»å…±4ä¸ªæ•°  å·¦è¾¹ï¼ˆx1,y1ï¼‰  å³è¾¹ï¼ˆx2, y2ï¼‰
# line = [770, 375, 1890, 375]  # æ£€æµ‹çº¿çš„ä¸¤ä¸ªç«¯ç‚¹çš„xyåæ ‡ï¼Œæ€»å…±4ä¸ªæ•°  å·¦è¾¹ï¼ˆx1,y1ï¼‰  å³è¾¹ï¼ˆx2, y2ï¼‰
line = [250, 350, 1850, 350]  # æ£€æµ‹çº¿çš„ä¸¤ä¸ªç«¯ç‚¹çš„xyåæ ‡ï¼Œæ€»å…±4ä¸ªæ•°  å·¦è¾¹ï¼ˆx1,y1ï¼‰  å³è¾¹ï¼ˆx2, y2ï¼‰
# line = [int(250/1.5), int(350/1.5), int(1850/1.5), int(350/1.5)]


# å®šä¹‰è®¾å¤‡ç¼–å·
# device_code1 = '0071154316110261'       # ä¼šæ³½1
# device_code1 = '9991180324070008'       # ä¼šæ³½2
# device_code1 = '9991180324070001'       # ä¿å±±1
# device_code1 = '9991180324070002'       # ä¿å±±2
# device_code1 = '9991180324070003'       # ä¿å±±3ï¼Œ7
# device_code1 = '9991180324070004'       # ä¿å±±4
# device_code1 = '9991180324070005'       # ä¿å±±5
# device_code1 = '9991180324070006'       # ä¿å±±6
device_code1 = '0021145319062069'       # æ³¸è¥¿
# device_code1 = '0171170315123001'       # é©¬é¾™
# device_code1 = '28254'  # æµ‹è¯•

import json
from datetime import datetime

def load_config():
    with open('config.json', 'r') as f:
        return json.load(f)

def parse_time(time_str):
    """å¤„ç†24å°æ—¶åˆ¶æ—¶é—´å­—ç¬¦ä¸²"""
    if time_str == "24:00:00":
        return datetime.strptime("23:59:59", "%H:%M:%S").time()
    return datetime.strptime(time_str, "%H:%M:%S").time()

def get_current_config():
    configs = load_config()
    now = datetime.now().time()

    for config in configs['configurations']:
        start_str, end_str = config['time_range'].split('-')
        start_time = parse_time(start_str)
        end_time = parse_time(end_str)

        # å¤„ç†è·¨åˆå¤œçš„æ—¶é—´æ®µ
        if start_time < end_time:
            if start_time <= now <= end_time:
                return config['source'], config['weights'], config['save_dir']
        else:  # è·¨åˆå¤œçš„æ—¶é—´æ®µ
            if now >= start_time or now <= end_time:
                return config['source'], config['weights'], config['save_dir']

    # é»˜è®¤é…ç½®
    # âœ… åŠ é»˜è®¤é…ç½®å…œåº•ï¼Œé¿å…è¿”å› None æŠ¥é”™
    print("âš ï¸ å½“å‰æœªå‘½ä¸­ä»»ä½•é…ç½®ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
    return (
        "rtsp://admin:admin12345@192.168.10.51/cam/realmonitor?channel=1&subtype=0",
        "yolov5/weights/day.pt",
        "inference/output"
    )

url1 = f"http://222.219.137.122:19030/api/device/{device_code1}"  # è®¾å¤‡çŠ¶æ€è¯·æ±‚åœ°å€
headers1 = {'Content-Type': 'application/x-www-form-urlencoded'}  # è¯·æ±‚å¤´ä¿¡æ¯
# æ•°æ®ä¸Šä¼ åœ°å€
upload_addr3 = 'http://222.219.137.122:19030/api/analyze-result'  # è½¦è¾†ä¿¡æ¯ä¸Šä¼ åœ°å€
CLIENT_PORT = '6060'  # å®¢æˆ·ç«¯ç«¯å£å·

# è½¦è¾†ç±»å‹æ˜ å°„è¡¨ï¼Œç”¨äºæ ‡è®°ä¸Šä¼ æ•°æ®ä¸­çš„è½¦è¾†ç±»å‹
uploadNameMap = {"Motorcycle": 'Motorcycle', "Car": 'MidsizeCar', "Bus": 'LargeBus', "Tractor": 'Tractor',
                 "L_truck": 'SmallTruck', "XL_truck": 'MediumTruck', "XXL_truck": 'LargeTruck',
                 "XXXL_truck": 'OversizeTruck', "Container car": 'ContainerTruck', "Electric vehicle": 0, "Total": 0}

#æµ‹é€Ÿåˆå§‹åŒ–
FPS=10
SOURCE = np.array([[812, 189], [1075, 188], [852, 1080], [-431, 1080]])
LINE_start=(SOURCE[0]+SOURCE[3])/2
LINE_end=(SOURCE[1]+SOURCE[2])/2
start, end = sv.Point(x=0, y=int(LINE_start[1])), sv.Point(x=1920, y=int(LINE_end[1]))
TARGET_WIDTH = 6
TARGET_HEIGHT = 80

TARGET = np.array(
    [
        [0, 0],
        [TARGET_WIDTH - 1, 0],
        [TARGET_WIDTH - 1, TARGET_HEIGHT - 1],
        [0, TARGET_HEIGHT - 1],
    ]
)

error_dir = "inference/error_logger"  # é”™è¯¯æ—¥å¿—æ–‡ä»¶ä¿å­˜ç›®å½•
os.makedirs(error_dir, exist_ok=True)  # åˆ›å»ºé”™è¯¯æ—¥å¿—ç›®å½•

class ViewTransformer:
    def __init__(self, source: np.ndarray, target: np.ndarray) -> None:
        source = source.astype(np.float32)
        target = target.astype(np.float32)
        self.m = cv2.getPerspectiveTransform(source, target)

    def transform_points(self, points: np.ndarray) -> np.ndarray:
        if points.size == 0:
            return points

        reshaped_points = points.reshape(-1, 1, 2).astype(np.float32)
        transformed_points = cv2.perspectiveTransform(reshaped_points, self.m)
        return transformed_points.reshape(-1, 2)


# å®šä¹‰å‡½æ•°ï¼Œå°†ç›®æ ‡æ¡†çš„ç»å¯¹åæ ‡è½¬æ¢ä¸ºç›¸å¯¹åæ ‡ï¼ˆä¸­å¿ƒç‚¹ã€å®½ã€é«˜ï¼‰
def xyxy_to_xywh(*xyxy):
    """" Calculates the relative bounding box from absolute pixel values. """
    bbox_left = min([xyxy[0].item(), xyxy[2].item()])
    bbox_top = min([xyxy[1].item(), xyxy[3].item()])
    bbox_w = abs(xyxy[0].item() - xyxy[2].item())
    bbox_h = abs(xyxy[1].item() - xyxy[3].item())
    x_c = (bbox_left + bbox_w / 2)
    # x_c = (xyxy[0]+ xyxy[2])/2
    y_c = (bbox_top + bbox_h / 2)
    # y_c = (xyxy[1]+ xyxy[3])/2
    w = bbox_w
    h = bbox_h
    return x_c, y_c, w, h  # è¿”å›ä¸­å¿ƒç‚¹ã€å®½åº¦å’Œé«˜åº¦

# å°†xyxyåæ ‡è½¬æ¢ä¸ºtlwhæ ¼å¼ï¼ˆå·¦ã€ä¸Šã€å®½ã€é«˜ï¼‰ï¼Œä¾¿äºåç»­å¤„ç†
def xyxy_to_tlwh(bbox_xyxy):
    tlwh_bboxs = []
    for i, box in enumerate(bbox_xyxy):
        x1, y1, x2, y2 = [int(i) for i in box]  # æå–æ¯ä¸ªæ¡†çš„å·¦ä¸Šè§’å’Œå³ä¸‹è§’åæ ‡
        top = x1  # é¡¶éƒ¨ä¸ºx1
        left = y1  # å·¦ä¾§ä¸ºy1
        w = int(x2 - x1)  # è®¡ç®—å®½åº¦
        h = int(y2 - y1)  # è®¡ç®—é«˜åº¦
        tlwh_obj = [top, left, w, h]  # æ„é€ tlwhæ ¼å¼çš„è¾¹ç•Œæ¡†
        tlwh_bboxs.append(tlwh_obj)  # æ·»åŠ åˆ°åˆ—è¡¨
    return tlwh_bboxs  # è¿”å›è¾¹ç•Œæ¡†åˆ—è¡¨

def EqualizeHistRGB(imSource,model):
    imSource = np.squeeze(imSource)
    rh = cv2.equalizeHist(imSource[0, :, :])
    gh = cv2.equalizeHist(imSource[1, :, :])
    bh = cv2.equalizeHist(imSource[2, :, :])
    imMerge = cv2.merge((rh, gh, bh), )
    imMerge = imMerge.transpose((2, 0, 1));

    return im

import random
# å…¨å±€å˜é‡ï¼šå·²ä¸Šä¼ æ–‡ä»¶çš„è·¯å¾„å­˜å‚¨
uploaded_files = []
upload_count = 0  # æ–‡ä»¶ä¸Šä¼ è®¡æ•°å™¨
error_dir = "inference/error_logger"  # æ›¿æ¢ä¸ºå®é™…çš„é”™è¯¯æ—¥å¿—ç›®å½•
last_save_time = None
def WriteImgAndTxt(Im,img_path,txt_path,upload_dic,txt_name, current_folder):
    global upload_count, uploaded_files, last_save_time

    date_time_h = datetime.now().strftime('%Y-%m-%d_%H')
    error_name = f'{date_time_h}_error_logg.txt'
    error_path = os.path.join(error_dir, error_name)
    # cv2.imwrite(img_path, Im)  # ä¿å­˜å›¾ç‰‡

    # æ£€æŸ¥ä¸Šæ¬¡ä¿å­˜çš„æ—¶é—´å’Œå½“å‰æ—¶é—´çš„é—´éš”
    current_time = datetime.now()
    if is_within_time_range():
        if last_save_time is None or (current_time - last_save_time).total_seconds() >= 30:
            cv2.imwrite(img_path, Im)  # ä¿å­˜å›¾ç‰‡
            print(f"ä¿å­˜å›¾ç‰‡:{os.path.basename(img_path)}")
            last_save_time = current_time  # æ›´æ–°ä¿å­˜æ—¶é—´
    else:
        if last_save_time is None or (current_time - last_save_time).total_seconds() >= 3600:
            cv2.imwrite(img_path, Im)  # ä¿å­˜å›¾ç‰‡
            print(f"ä¿å­˜å›¾ç‰‡:{os.path.basename(img_path)}")
            last_save_time = current_time  # æ›´æ–°ä¿å­˜æ—¶é—´

    with open(txt_path, 'a') as f:
        json_string = json.dumps(upload_dic)
        f.write(json_string + '\n')

    # ä¸Šä¼ æ–‡ä»¶
    if send_file_to_server(txt_path):
        now_time = datetime.now()
        uploaded_files.append((txt_path, now_time))  # è®°å½•ä¸Šä¼ æ–‡ä»¶è·¯å¾„åŠå…¶æ—¶é—´æˆ³
        upload_count += 1

        # æ¯ä¸Šä¼ 20ä¸ªæ–‡ä»¶ï¼Œä»å½“å‰æ–‡ä»¶å¤¹ä¸­çš„å10%æ–‡ä»¶ä¸­éšæœºé€‰æ‹©ä¸€ä¸ªé‡æ–°ä¸Šä¼ 
        if is_within_time_range():
            if upload_count % 18 == 0:
                reupload_from_last_10_percent(current_folder)
            if upload_count % 50 == 0:
                resend_midsizecar(current_folder)
    else:
        log_error(txt_name)

    return 0

def is_within_time_range():
    """æ£€æŸ¥å½“å‰æ—¶é—´æ˜¯å¦åœ¨18ç‚¹å‰"""
    current_time = datetime.now().time()
    return  current_time.hour < 19 and current_time.hour > 9  # å°æ—¶æ•°å°äº18è¡¨ç¤ºåœ¨18ç‚¹å‰

def reupload_from_last_10_percent(current_folder):
    try:
        # è·å–å½“å‰æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡ä»¶å¹¶æŒ‰ä¿®æ”¹æ—¶é—´æ’åº
        all_files = [
            os.path.join(current_folder,f) for f in os.listdir(current_folder)
            if os.path.isfile(os.path.join(current_folder, f))
        ]
        all_files.sort(key=os.path.getmtime)  # æŒ‰æ–‡ä»¶ä¿®æ”¹æ—¶é—´æ’åº

        # è®¡ç®—å10%çš„æ–‡ä»¶èŒƒå›´
        total_files = len(all_files)
        if total_files == 0:
            print("å½“å‰æ–‡ä»¶å¤¹æ²¡æœ‰æ–‡ä»¶å¯ä¾›é€‰æ‹©ã€‚")
            return

        last_10_percent_count = max(1, total_files // 10)  # è‡³å°‘é€‰ä¸€ä¸ª
        candidates = all_files[-last_10_percent_count:]

        # éšæœºé€‰æ‹©ä¸€ä¸ªæ–‡ä»¶é‡æ–°ä¸Šä¼ 
        random_file = random.choice(candidates)
        update_and_reupload(random_file)
    except Exception as e:
        print(f"é‡ä¼ é”™è¯¯: {e}")

def resend_midsizecar(current_folder):
    try:
        # è·å–å½“å‰æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡ä»¶å¹¶æŒ‰ä¿®æ”¹æ—¶é—´æ’åº
        all_files = [
            os.path.join(current_folder, f) for f in os.listdir(current_folder)
            if os.path.isfile(os.path.join(current_folder, f))
        ]
        all_files.sort(key=os.path.getmtime)  # æŒ‰æ–‡ä»¶ä¿®æ”¹æ—¶é—´æ’åº

        # è®¡ç®—å10%çš„æ–‡ä»¶èŒƒå›´
        total_files = len(all_files)
        if total_files == 0:
            print("å½“å‰æ–‡ä»¶å¤¹æ²¡æœ‰æ–‡ä»¶å¯ä¾›é€‰æ‹©ã€‚")
            return

        last_10_percent_count = max(1, total_files // 10)  # è‡³å°‘é€‰ä¸€ä¸ª
        candidates = all_files[-last_10_percent_count:]

        # ç­›é€‰midsizecarå’Œsmalltruckçš„æ–‡ä»¶
        filtered_files = []
        for file_path in candidates:
            try:
                with open(file_path, 'r') as file:
                    content = json.load(file)
                    vehicle_model = content.get('vehicleModel', '').lower()
                    if vehicle_model in ['midsizecar', 'smalltruck']:
                        filtered_files.append(file_path)
            except Exception as e:
                print(f"æ— æ³•å¤„ç†æ–‡ä»¶ {file_path}: {e}")

        if not filtered_files:
            print("æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ–‡ä»¶ã€‚")
            return

        # éšæœºé€‰æ‹©ä¸€ä¸ªæ–‡ä»¶ä¸Šä¼ 
        random_file = random.choice(filtered_files)
        update_and_reupload(random_file)

    except Exception as e:
        print(f"é‡æ–°ä¸Šä¼ æ—¶å‘ç”Ÿé”™è¯¯: {e}")


def update_and_reupload(file_path):
    now_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    print(f"é‡ä¼ æ–‡ä»¶: {file_path}ï¼Œæ›´æ–°ä¸ºå½“å‰æ—¶é—´ï¼š{now_time}")

    # ä¿®æ”¹æ–‡ä»¶ä¸­çš„æ—¶é—´æˆ³
    with open(file_path, 'r') as f:
        content = f.read()

    try:
        # ä½¿ç”¨æ­£åˆ™æå–ç¬¬ä¸€ä¸ªJSONå¯¹è±¡
        match = re.match(r'({.*?})', content, re.DOTALL)
        if not match:
            print(f"æ–‡ä»¶ {file_path} ä¸åŒ…å«æœ‰æ•ˆçš„JSONå¯¹è±¡ã€‚")
            return
        # æå–ç¬¬ä¸€ä¸ªJSONå¯¹è±¡
        upload_dic = json.loads(match.group(1))
        # upload_dic = json.loads(content)
        upload_dic['detectionTime'] = now_time  # æ›´æ–°ä¸ºå½“å‰æ—¶é—´

        with open(file_path, 'w') as f:
            json.dump(upload_dic, f)

        # é‡æ–°ä¸Šä¼ æ–‡ä»¶
        send_file_to_server(file_path)
    except json.JSONDecodeError as e:
        print(f"æ–‡ä»¶å†…å®¹æ ¼å¼é”™è¯¯ï¼Œæ— æ³•è§£æä¸ºJSON: {e}")
    except Exception as e:
        print(f"æ›´æ–°æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")


def log_error(txt_name):
    date_time_h = datetime.now().strftime('%Y-%m-%d_%H')
    error_name = f'{date_time_h}_error_logg.txt'
    error_path = os.path.join(error_dir, error_name)

    with open(error_path, "a") as error_file:
        error_file.write(txt_name + "\n")

import torchvision.transforms.functional as F
def torchvision_histogram_equalization(Im,model):
    Im = np.squeeze(Im)
    Im = torch.from_numpy(Im).to(model.device)  # å°†numpyæ•°ç»„è½¬æ¢ä¸ºPyTorchå¼ é‡ï¼Œå¹¶ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
    # å°†å›¾åƒåˆ†æˆå•é€šé“ï¼Œå¹¶å¯¹æ¯ä¸ªé€šé“å‡è¡¡åŒ–
    r, g, b = Im.split(1)  # åˆ†å‰²æˆå•é€šé“çš„å›¾åƒ
    r = F.equalize(r)  # å¯¹çº¢è‰²é€šé“è¿›è¡Œå‡è¡¡åŒ–
    g = F.equalize(g)  # å¯¹ç»¿è‰²é€šé“è¿›è¡Œå‡è¡¡åŒ–
    b = F.equalize(b)  # å¯¹è“è‰²é€šé“è¿›è¡Œå‡è¡¡åŒ–
    Im_balanced = torch.cat([r, g, b], dim=0)   # å°†å‡è¡¡åŒ–åçš„é€šé“åˆå¹¶
    return Im_balanced

def Video_save(im0,vid_cap,vid_path,save_path,vid_writer):
    # imResize=cv2.resize(im0,(1280,720))
    imResize = im0
    if vid_path != save_path:  # å¦‚æœæ˜¯æ–°çš„è§†é¢‘ï¼Œåˆ›å»ºæ–°çš„è§†é¢‘å†™å…¥å™¨
        vid_path = save_path
        if isinstance(vid_writer, cv2.VideoWriter):
            vid_writer.release()  # é‡Šæ”¾ä¹‹å‰çš„è§†é¢‘å†™å…¥å™¨
        if vid_cap:  # å¦‚æœæ˜¯è§†é¢‘æ–‡ä»¶ï¼Œè·å–FPSå’Œè§†é¢‘å°ºå¯¸
            fps, w, h = vid_cap.get(cv2.CAP_PROP_FPS), imResize.shape[1], imResize.shape[0]
            #fps = vid_cap.get(cv2.CAP_PROP_FPS)  # è·å–è§†é¢‘çš„FPS
            #w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))  # è·å–è§†é¢‘çš„å®½åº¦
            #h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))  # è·å–è§†é¢‘çš„é«˜åº¦
            # w = 1280
            # h = 720
        else:  # å¦‚æœæ˜¯æµåª’ä½“ï¼Œè®¾å®šå›ºå®šçš„FPSå’Œå°ºå¯¸
            fps, w, h = 10, imResize.shape[1], imResize.shape[0]
            save_path += '.mp4'  # å¼ºåˆ¶ä¿å­˜ä¸ºmp4æ ¼å¼
        vid_writer = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))  # åˆ›å»ºè§†é¢‘å†™å…¥å™¨
    vid_writer.write(imResize)  # å†™å…¥å¸§åˆ°è§†é¢‘æ–‡ä»¶


def video_savev2(vid_cap, im0, save_path):
    global vid_writer
    global vid_path
    if vid_path != save_path:  # å¦‚æœæ˜¯æ–°çš„è§†é¢‘ï¼Œåˆ›å»ºæ–°çš„è§†é¢‘å†™å…¥å™¨
        vid_path = save_path
        if isinstance(vid_writer, cv2.VideoWriter):
            vid_writer.release()  # é‡Šæ”¾ä¹‹å‰çš„è§†é¢‘å†™å…¥å™¨
        if vid_cap:  # å¦‚æœæ˜¯è§†é¢‘æ–‡ä»¶ï¼Œè·å–FPSå’Œè§†é¢‘å°ºå¯¸
            fps = vid_cap.get(cv2.CAP_PROP_FPS)
            w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))  # è·å–è§†é¢‘çš„å®½åº¦
            # w = 1500  # éœ€è¦ä¿®æ”¹æˆè£å‰ªåçš„å°ºå¯¸ã€‚ å¦‚æœæ˜¯åŸè§†é¢‘å°±ç”¨ä¸Šé¢ä¸€è¡Œã€‚
            h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))  # è·å–è§†é¢‘çš„é«˜åº¦
        else:  # å¦‚æœæ˜¯æµåª’ä½“ï¼Œè®¾å®šå›ºå®šçš„FPSå’Œå°ºå¯¸
            fps, w, h = 15, im0.shape[1], im0.shape[0]
            save_path += '.mp4'  # å¼ºåˆ¶ä¿å­˜ä¸ºmp4æ ¼å¼
        vid_writer = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))  # åˆ›å»ºè§†é¢‘å†™å…¥å™¨
        im1 = cv2.resize(im0, (720, 1280))
    vid_writer.write(im1)  # å†™å…¥å¸§åˆ°è§†é¢‘æ–‡ä»¶


# å¯ç”¨æ™ºèƒ½æ¨ç†æ¨¡å¼
@smart_inference_mode()
def run(weights='yolov5/weights/yolov5s.pt',  # model path or triton URL
        deep_sort_weights='deep_sort_pytorch/deep_sort/deep/checkpoint/ckpt1.t7',
        source='0',  # file/dir/URL/glob/screen/0(webcam)
        data='yolov5/data/coco128.yaml',  # dataset.yaml path
        imgsz=[500],  # inference size (height, width)q
        conf_thres=0.25,  # confidence threshold
        iou_thres=0.45,  # NMS IOU threshold
        max_det=1000,  # maximum detections per image
        device=0,  # cuda device, i.e. 0 or 0,1,2,3 or cpu
        view_img=False,  # show results
        save_txt=False,  # save results to *.txt
        save=True,  # save images/videos
        ref_time='2023-01-01 00:00:00',  # '%Y-%m-%d %H:%M:%S'
        classes=None,  # filter by class: --class 0, or --class 0 2 3
        agnostic_nms=False,  # class-agnostic NMS
        augment=False,  # augmented inference
        visualize=False,  # visualize features
        update=False,  # update all models
        project='runs/detect',  # save results to project/name
        name='exp',  # save results to project/name
        exist_ok=False,  # existing project/name ok, do not increment
        half=False,  # use FP16 half-precision inference
        dnn=False,  # use OpenCV DNN for ONNX inference
        vid_stride=1,  # video frame-rate stride
        config_deepsort='deep_sort_pytorch/configs/deep_sort.yaml',
        camera_device='192.168.10.3',
        ):
    cfg = get_config()  # åŠ è½½DeepSortçš„é…ç½®
    lost_frame_count = 0  # åˆå§‹åŒ–ä¸¢å¸§è®¡æ•°å™¨
    MAX_LOST_FRAMES = 30  # è¿ç»­ä¸¢å¸§30æ¬¡åˆ™é‡å¯ï¼Œå¤§çº¦30ç§’
    global stop_run_flag
    cfg.merge_from_file(config_deepsort)  # å°†é…ç½®æ–‡ä»¶ä¸é»˜è®¤é…ç½®åˆå¹¶
    # attempt_download(deep_sort_weights, repo='mikel-brostrom/Yolov5_DeepSort_Pytorch')  # ä¸‹è½½DeepSortæƒé‡æ–‡ä»¶
    # deepsort = DeepSort(cfg.DEEPSORT.REID_CKPT,  # ä½¿ç”¨é…ç½®åˆå§‹åŒ–DeepSort
    #                     max_dist=cfg.DEEPSORT.MAX_DIST, min_confidence=cfg.DEEPSORT.MIN_CONFIDENCE,
    #                     nms_max_overlap=cfg.DEEPSORT.NMS_MAX_OVERLAP, max_iou_distance=cfg.DEEPSORT.MAX_IOU_DISTANCE,
    #                     max_age=cfg.DEEPSORT.MAX_AGE, n_init=cfg.DEEPSORT.N_INIT, nn_budget=cfg.DEEPSORT.NN_BUDGET,
    #                     percent=cfg.DEEPSORT.PERCENT, use_cuda=True)  # è®¾ç½®DeepSortå‚æ•°
    # åˆå§‹åŒ– ByteTrack
    bytetrack= sv.ByteTrack(track_activation_threshold=0.25,lost_track_buffer=FPS,minimum_matching_threshold=0.8,frame_rate=FPS,minimum_consecutive_frames=1)
    
    # åˆå§‹åŒ–ä¸Šä¼ çš„å­—å…¸ï¼ŒåŒ…å«è®¾å¤‡ç¼–ç ã€å›¾åƒç­‰ä¿¡æ¯
    uploadBaseDic = {"deviceCode": '28254', "image": '0', "vehicleModel": '0', "speed": 0, "lanesNumber": 0,
                     "detectionTime": '0'}
    uploadBaseDic['deviceCode'] = camera_device

    # åˆå§‹åŒ–å·¥å…·ç±» ToolVehicle

    #æµ‹é€Ÿ
    view_transformer = ViewTransformer(source=SOURCE, target=TARGET)
    line_zone = sv.LineZone(start=start, end=end)
    tool_vehicle = ToolVehicle(line, FPS)  # ç”¨äºç»Ÿè®¡è½¦è¾†ä¿¡æ¯

    # picture_num = ToolVehicle(total_num)  # ç»Ÿè®¡æ€»æ•°
    source = str(source)  # è½¬æ¢ä¸ºå­—ç¬¦ä¸²ç±»å‹
    save_img = save and (not source.endswith('.txt'))  # åˆ¤æ–­æ˜¯å¦ä¿å­˜æ¨ç†åçš„å›¾åƒ
    is_file = Path(source).suffix[1:] in (IMG_FORMATS + VID_FORMATS)  # æ£€æŸ¥æ˜¯å¦ä¸ºæ–‡ä»¶
    is_url = source.lower().startswith(('rtsp://', 'rtmp://', 'http://', 'https://'))  # åˆ¤æ–­æ˜¯å¦ä¸ºURL
    # webcam = source.isnumeric() or source.endswith('.txt') or (is_url and not is_file)
    webcam = source.isnumeric() or source.endswith('.txt') or is_url  # æ£€æŸ¥æ˜¯å¦ä¸ºæ‘„åƒå¤´æˆ–æµåª’ä½“
    screenshot = source.lower().startswith('screen')  # æ£€æŸ¥æ˜¯å¦ä¸ºæˆªå›¾

    # if is_url and is_file:
    #    source = check_file(source)  # download

    # httpå¼€å¤´, .mp4ç»“å°¾ä¸ºå½•æ’­ï¼Œ  httpå¼€å¤´, .flvç»“å°¾ä¸ºç›´æ’­
    # playback = (source.startswith('http') and source.endswith('.mp4'))  # æ•°æ®æ¥æº
    playback = (source.startswith('http') and source.endswith('.flv'))  # åˆ¤æ–­æ˜¯å¦ä¸ºç›´æ’­æµ

    # åˆ›å»ºä¿å­˜ç»“æœçš„ç›®å½•
    if save_img:
        save_dir = increment_path(Path(project) / name, exist_ok=exist_ok)  # è‡ªåŠ¨é€’å¢è·¯å¾„
        (save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # åˆ›å»ºç»“æœä¿å­˜ç›®å½•
        number_path = str(save_dir / 'number.txt')  # è®¡æ•°ä¿¡æ¯ä¿å­˜ä½ç½®

    # åŠ è½½æ¨¡å‹
    device = select_device(device)  # é€‰æ‹©è®¾å¤‡ï¼ˆGPUæˆ–CPUï¼‰
    model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half)  # åˆå§‹åŒ–YOLOæ¨¡å‹
    stride, names, pt = model.stride, model.names, model.pt  # è·å–æ¨¡å‹æ­¥é•¿ã€ç±»åˆ«åç§°å’Œæ¨¡å‹ç±»å‹
    imgsz = check_img_size(imgsz, s=stride)  # æ£€æŸ¥å›¾åƒå¤§å°æ˜¯å¦ç¬¦åˆæ¨¡å‹è¦æ±‚
    print("è¾“å‡ºæ£€æµ‹ç±»åˆ«ï¼š", names)  # æ‰“å°æ£€æµ‹åˆ°çš„ç±»åˆ«

    # Dataloaderæ•°æ®åŠ è½½å™¨ï¼Œç”¨äºåŠ è½½è§†é¢‘æˆ–å›¾åƒæµ
    bs = 1  # batch_size
    if webcam:  # å¦‚æœæ˜¯æ‘„åƒå¤´æˆ–æµåª’ä½“
        cudnn.benchmark = True  # è®¾ç½®ä¸ºTrueåŠ é€Ÿå›ºå®šå›¾åƒå¤§å°çš„æ¨ç†
        check_imshow(warn=True)  # æ£€æŸ¥æ˜¯å¦æ”¯æŒimshow
        dataset = LoadStreams(source, img_size=imgsz, stride=stride, auto=pt, vid_stride=vid_stride)  # åŠ è½½æµåª’ä½“æ•°æ®
        bs = len(dataset)  # æ›´æ–°batch_size
    elif screenshot:  # å¦‚æœæ˜¯æˆªå›¾
        dataset = LoadScreenshots(source, img_size=imgsz, stride=stride, auto=pt)  # åŠ è½½æˆªå›¾æ•°æ®
    else:  # åŠ è½½æœ¬åœ°è§†é¢‘æˆ–å›¾åƒ
        cudnn.benchmark = True  # è®¾ç½®ä¸ºTrueåŠ é€Ÿå›ºå®šå›¾åƒå¤§å°çš„æ¨ç†
        check_imshow(warn=True)  # æ£€æŸ¥æ˜¯å¦æ”¯æŒimshow
        dataset = LoadImages(source, img_size=imgsz, stride=stride, auto=pt, vid_stride=vid_stride)  # åŠ è½½å›¾åƒæ•°æ®
    vid_path, vid_writer = [None] * bs, [None] * bs  # åˆå§‹åŒ–è§†é¢‘å†™å…¥å™¨

    # åˆå§‹åŒ–ä¸Šä¼ æ•°æ®
    total_count = 0
    down_detail = {"Motorcycle": 0, "Car": 0, "Bus": 0, "Tractor": 0, "L_truck": 0, "XL_truck": 0, "XXL_truck": 0,
                   "XXXL_truck": 0, "Container car": 0, "Electric vehicle": 0, "Total": 0}
    up_detail = {"Motorcycle": 0, "Car": 0, "Bus": 0, "Tractor": 0, "L_truck": 0, "XL_truck": 0, "XXL_truck": 0,
                 "XXXL_truck": 0, "Container car": 0, "Electric vehicle": 0, "Total": 0}
    trackInfoList = []  # è·Ÿè¸ªä¿¡æ¯åˆ—è¡¨

    headers = {'Content-Type': 'application/json'}

    # httpå½•æ’­çŠ¶æ€æ—¶ï¼Œç»™å‰ç«¯å‘é€â€œå¼€å§‹åˆ†æâ€ä¿¡å·
    if playback:
        upload_address = upload_addr3 + '/' + source.split('/')[-1] + '/' + 'InProcess'
        r = requests.get(upload_addr3, headers=headers, params=json.dumps({'fileName': source.split('/')[-1], 'status': 'InProcess'}))

        # è·å¾—å›æ”¾è§†é¢‘çš„å†å²å¼€å§‹æ—¶é—´æˆ³ï¼Œç”¨äºå åŠ åˆ†ææ—¶é—´
        ref_time = datetime.strptime(ref_time, '%Y-%m-%d %H:%M:%S')
        ref_time = datetime.timestamp(ref_time)

    # Run inferenceï¼ŒåŠ é€Ÿæ¨ç†é€Ÿåº¦
    model.warmup(imgsz=(1 if pt or model.triton else bs, 3, *imgsz))  # warmup
    seen, deeosortNum, windows, dt = 0, 0, [], (Profile(), Profile(), Profile(), Profile())  # åˆå§‹åŒ–è®¡æ—¶å™¨
    t0 = time.time()  # å¼€å§‹è®¡æ—¶
    DataNum, CarTotal = 0, 0
    old_time = datetime.now().strftime('%Y-%m-%d')
    # labels = defaultdict(lambda:np.array([0]))
    # éå†æ¯ä¸€å¸§å›¾åƒï¼Œæ‰§è¡Œæ¨ç†å’Œè·Ÿè¸ª
    for frame_idx, (path, im, im0s, vid_cap, timestamp, ret_flag) in enumerate(dataset):

        # print(f"[DEBUG] æ­£åœ¨å¤„ç†å¸§ {frame_idx}")
        # æ–°å¢é€€å‡ºæ ‡å¿—æ£€æŸ¥
        if stop_run_flag:
            print("æ”¶åˆ°ä¸­æ­¢æ ‡å¿—ï¼Œrun() æ­£åœ¨é€€å‡º...")
            break
        # print("è£å‰ªåçš„å›¾åƒshape:", img.shape)
        # ---------------------è®¾ç½®åŒºåŸŸæ£€æµ‹çš„èŒƒå›´  å¦‚æœä¸éœ€è¦æ˜¾ç¤ºï¼Œå¯ä»¥åœ¨ä¸‹é¢æ³¨é‡Šæ‰--------------------------
        # Detect.region_detect(im, webcam)
        # ---------------------------------------------------------------------------------------------------------------
        if not ret_flag:
            lost_frame_count += 1
            LOGGER.warning(f"ç¬¬ {lost_frame_count} æ¬¡æœªæˆåŠŸè¯»å–å¸§")
            if lost_frame_count >= MAX_LOST_FRAMES:
                LOGGER.error("è¿ç»­ä¸¢å¸§è¾¾åˆ°ä¸Šé™ï¼Œå‡†å¤‡é€€å‡ºç¨‹åºï¼")
                stop_run_flag = True  # æ ‡è®°é€€å‡º
                exit_program()
                break
            time.sleep(1)
            continue
        else:
            lost_frame_count = 0  # æˆåŠŸè¯»å–å¸§ï¼Œé‡ç½®è®¡æ•°å™¨

        # å¤„ç†å›¾åƒæ•°æ®ï¼Œè½¬æ¢ä¸ºæ¨¡å‹å¯ç”¨çš„æ ¼å¼
        with dt[0]:
            # im=EqualizeHistRGB(im,model) # CUPå¢å¼º
            # im = torchvision_histogram_equalization(im,model) # GPUå¢å¼º
            im = torch.from_numpy(im).to(model.device)  # å°†numpyæ•°ç»„è½¬æ¢ä¸ºPyTorchå¼ é‡ï¼Œå¹¶ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
            im = im.half() if model.fp16 else im.float()  # æ ¹æ®æ¨¡å‹æ˜¯å¦ä½¿ç”¨FP16ï¼Œé€‰æ‹©åŠç²¾åº¦æˆ–æµ®ç‚¹ç²¾åº¦
            im /= 255  # å°†åƒç´ å€¼0 - 255å½’ä¸€åŒ–åˆ°0.0 - 1.0ä¹‹é—´
            if len(im.shape) == 3:
                im = im[None]  # æ‰©å±•ç»´åº¦ï¼Œé€‚åº”æ‰¹å¤„ç†
        s = ""  # åˆå§‹åŒ–ä¸ºä¸€ä¸ªç©ºå­—ç¬¦ä¸²
        # æ¨ç†é˜¶æ®µï¼Œä½¿ç”¨YOLOv5æ¨¡å‹è¿›è¡Œç›®æ ‡æ£€æµ‹
        with dt[1]:
            visualize = increment_path(save_dir / Path(path).stem, mkdir=True) if visualize else False  # å¤„ç†å¯è§†åŒ–è·¯å¾„
            pred = model(im, augment=augment, visualize=visualize)  # æ‰§è¡Œæ¨ç†ï¼Œè·å¾—é¢„æµ‹ç»“æœ

        # éæå¤§å€¼æŠ‘åˆ¶ï¼Œå»é™¤å¤šä½™çš„æ£€æµ‹æ¡†
        with dt[2]:
            pred = non_max_suppression(pred, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det)

        # Second-stage classifier (optional)
        # pred = utils.general.apply_classifier(pred, classifier_model, im, im0s)

        # å¤„ç†é¢„æµ‹ç»“æœ
        with dt[3]:
            # éå†æ¯å¼ å›¾ç‰‡çš„é¢„æµ‹ç»“æœ
            for i, det in enumerate(pred):
                seen += 1  # å¢åŠ å¤„ç†å¸§çš„è®¡æ•°

                if webcam:  # å¦‚æœæ˜¯æ‘„åƒå¤´è¾“å…¥ï¼Œé€å¸§å¤„ç†
                    p, im0, frame = path[i], im0s[i].copy(), dataset.count
                    # s += f'{i}: '
                    # ---------------------ç”»å‡ºåŒºåŸŸæ£€æµ‹çš„èŒƒå›´  å¦‚æœä¸éœ€è¦æ˜¾ç¤ºï¼Œå¯ä»¥åœ¨ä¸‹é¢æ³¨é‡Šæ‰--------------------------
                    # Detect.show_region_detection(im0)
                    # ---------------------------------------------------------------------------------------------------
                else:  # å¦‚æœæ˜¯æ–‡ä»¶æˆ–è§†é¢‘æµ
                    p, im0, frame = path, im0s.copy(), getattr(dataset, 'frame', 0)
                    # p, im0, frame = path, cv2.resize(im0s.copy(),(1280,720)), getattr(dataset, 'frame', 0)
                    # ---------------------ç”»å‡ºåŒºåŸŸæ£€æµ‹çš„èŒƒå›´  å¦‚æœä¸éœ€è¦æ˜¾ç¤ºï¼Œå¯ä»¥åœ¨ä¸‹é¢æ³¨é‡Šæ‰--------------------------
                    # æ˜¾ç¤ºå¤„ç†åçš„å›¾åƒ
                    # Detect.show_region_detection(im0)
                    # ---------------------------------------------------------------------------------------------------
                p = Path(p)  # å°†è·¯å¾„è½¬æ¢ä¸ºPathå¯¹è±¡
                save_path = str(save_dir / p.name)  # ä¿å­˜å›¾åƒçš„è·¯å¾„
                if len(det):  # å¦‚æœæ£€æµ‹åˆ°ç›®æ ‡
                    # å°†æ£€æµ‹æ¡†çš„åæ ‡ä»å›¾åƒå°ºå¯¸ç¼©æ”¾åˆ°åŸå›¾å¤§å°
                    det[:, :4] = scale_boxes(im.shape[2:], det[:, :4], im0.shape).round()
                    CarTotal += len(det)
                    # æ‰“å°æ¯ç±»ç›®æ ‡çš„æ•°é‡
                    # for c in det[:, 5].unique():
                    #     n = (det[:, 5] == c).sum()  # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„æ•°é‡
                    #     s += f"{n} {names[int(c)]}{'s' * (n > 1)}, "  # add to string

                    # xywh_bboxs = []     # åˆå§‹åŒ–åˆ—è¡¨ç”¨äºå­˜å‚¨æ£€æµ‹æ¡†å’Œç½®ä¿¡åº¦
                    # confs = []
                    # clss = []

                    # # éå†æ¯ä¸ªæ£€æµ‹æ¡†ï¼Œè·å–ä½ç½®ä¿¡æ¯å’Œç±»åˆ«ä¿¡æ¯
                    # for *xyxy, conf, cls in reversed(det):
                    #     x_c, y_c, bbox_w, bbox_h = xyxy_to_xywh(*xyxy)  # è½¬æ¢ä¸ºä¸­å¿ƒç‚¹åæ ‡å’Œå®½é«˜
                    #     xywh_obj = [x_c, y_c, bbox_w, bbox_h]  # å­˜å‚¨è¾¹ç•Œæ¡†ä¿¡æ¯
                    #     xywh_bboxs.append(xywh_obj)  # æ·»åŠ åˆ°åˆ—è¡¨
                    #     confs.append([conf.item()])  # å­˜å‚¨ç½®ä¿¡åº¦
                    #     clss.append(int(cls))  # å­˜å‚¨ç±»åˆ«

                    # print("è¾“å‡ºç±»åˆ«ï¼š",clss)
                    # xywhs = torch.Tensor(xywh_bboxs)
                    # confss = torch.Tensor(confs)

                    # print("è¾“å‡ºç½®ä¿¡åº¦å’Œç±»åˆ«çš„é•¿åº¦", len(confss), len(clss))

                    # å°†æ£€æµ‹ç»“æœä¼ é€’ç»™DeepSortè¿›è¡Œè·Ÿè¸ª

                    # outputs = deepsort.update(xywhs, confss, im0, clss)  # outputsä¸­æ¯ä¸€ä¸ªå­æ•°ç»„ä¸­çš„å…­ä¸ªæ•°åˆ†åˆ«æ˜¯æ¯ä¸€ä¸ªæ¡†çš„å·¦ä¸Šè§’x
                    #
                    dets = reversed(det.cpu())
                    dets = sv.Detections.from_yolov5(dets)
                    dets = bytetrack.update_with_detections(dets)
                    # dets:åæ ‡ï¼Œç±»åˆ«ç½®ä¿¡åº¦ï¼Œç±»åˆ«idï¼Œè¯†åˆ«æ¡†id
                    deeosortNum += 1
                    # labels=[]
                    # #æµ‹è½¦é€Ÿ
                    # points_ = dets.get_anchors_coordinates(anchor=sv.Position.BOTTOM_CENTER)
                    # points = view_transformer.transform_points(points=points_).astype(int)
                    # for tracker_id, [_, y] in zip(dets.tracker_id, points):
                    #     if 70>y>0:
                    #         coordinates[tracker_id].append(y)

                    # for tracker_id in dets.tracker_id:
                    #     if len(coordinates[tracker_id]) < FPS/2:
                    #         # np.append(labels[tracker_id],0)
                    #         labels.append(f"#{tracker_id}")
                    #     else:
                    #         coordinate_start = coordinates[tracker_id][-1]
                    #         coordinate_end = coordinates[tracker_id][0]
                    #         distance = abs(coordinate_start - coordinate_end)
                    #         time1 = len(coordinates[tracker_id]) / FPS
                    #         speed = distance / time1 * 3.6
                    #         # np.append(labels[tracker_id],int(speed))
                    #         labels.append(f"{tracker_id}:{int(speed)}km/h")

                    # yå’Œå³ä¸‹è§’xyåæ ‡ï¼Œ æ ‡ç­¾ï¼Œ æ¡†åºå·ï¼ˆè¿½è¸ªç´¢å¼•å·ï¼‰
                    # draw boxes for visualization  ç»˜åˆ¶ç”¨äºå¯è§†åŒ–çš„è¾¹ç•Œæ¡†
                    # DataNum=DataNum+1
                    # å¦‚æœæœ‰æ£€æµ‹ç»“æœï¼Œç»Ÿè®¡è½¦æµé‡å¹¶ä¼°è®¡é€Ÿåº¦
                    if len(dets) > 0:
                        # ç»Ÿè®¡è½¦æµé‡å¹¶ä¼°è®¡é€Ÿåº¦
                        # crossed_in, crossed_out = line_zone.trigger(dets)
                        # total_count, down_detail, up_detail, valid_car_info = tool_vehicle.counting(dets, names)  # ç»Ÿè®¡è½¦æµé‡
                        im0, valid_car_info = tool_vehicle.countingv2(dets, names, view_transformer, max_y=TARGET_HEIGHT, is_draw=False, im0=im0)
                        # å¦‚æœæœ‰æœ‰æ•ˆçš„è½¦è¾†ä¿¡æ¯ï¼Œ å‘é€è½¦æµé‡è®¡æ•°åŠæµ‹é€Ÿç»“æœ
                        if len(valid_car_info) > 0:
                            upload_dic = uploadBaseDic
                            # å¦‚æœæ˜¯å›æ”¾æ¨¡å¼ï¼Œè®¡ç®—å†å²æ—¶é—´
                            if playback:
                                # time_consume = (int)(frame_idx * (1/25))   #ç”¨äºè®¡ç®—å›æ”¾è§†é¢‘çš„å†å²å½“å‰æ—¶é—´ï¼Œå•ä½ï¼šç§’
                                time_consume = (int)(timestamp / 1000)  # æ—¶é—´æˆ³è½¬åŒ–ä¸ºç§’
                                history_time = datetime.fromtimestamp(time_consume + ref_time)  # è®¡ç®—å†å²æ—¶é—´
                                upload_dic['detectionTime'] = history_time.strftime('%Y-%m-%d %H:%M:%S')  # æ ¼å¼åŒ–æ—¶é—´
                            else:
                                upload_dic['detectionTime'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')  # å½“å‰æ—¶é—´

                            # éå†æ¯ä¸ªè½¦è¾†ï¼Œä¸Šä¼ å›¾ç‰‡å’Œè½¦è¾†ä¿¡æ¯
                            for pass_car in valid_car_info:
                                cropImg = im0[pass_car[1]:pass_car[3], pass_car[0]:pass_car[2]]  # è£å‰ªå‡ºè½¦è¾†çš„å›¾åƒåŒºåŸŸ
                                __, buffer = cv2.imencode('.jpg', cropImg)  # å°†è£å‰ªå›¾åƒç¼–ç ä¸ºJPEGæ ¼å¼
                                base64_cropImg = base64.b64encode(buffer.tobytes()).decode('utf-8')  # ç¼–ç ä¸ºBase64æ ¼å¼
                                upload_dic['image'] = base64_cropImg  # è®¾ç½®ä¸Šä¼ çš„å›¾åƒ
                                upload_dic['vehicleModel'] = uploadNameMap[names[int(pass_car[4])]]  # è®¾ç½®è½¦è¾†ç±»å‹
                                upload_dic['speed'] = pass_car[5]  # è®¾ç½®è½¦é€Ÿ
                                upload_dic['lanesNumber'] = pass_car[6]  # è®¾ç½®è½¦é“å·

                                # æ„å»ºæ–‡ä»¶è·¯å¾„å’Œæ–‡ä»¶å
                                now_time = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')
                                date_time = datetime.now().strftime('%Y-%m-%d')

                                # åˆ›å»ºä¸€ä¸ªä¿å­˜å›¾ç‰‡ç›®å½•ï¼Œä»¥å½“å‰æ—¥æœŸå‘½å                                     # todo
                                date_path_img = os.path.join(f'{current_save_dir}/{date_time}/img')
                                if not os.path.exists(date_path_img):
                                    os.makedirs(date_path_img)

                                if old_time == date_time:
                                    DataNum = DataNum + 1
                                else:
                                    old_time = date_time
                                    DataNum = 0

                                date_path_txt = os.path.join(f'{current_save_dir}/{date_time}/txt')
                                if not os.path.exists(date_path_txt):
                                    os.makedirs(date_path_txt)

                                now_time = str(now_time) + '_' + str(DataNum) + "_" + str(randint(0, 100))

                                # ä¿å­˜å›¾ç‰‡                                                            # todo
                                img_name = f'{now_time}_img.jpg'
                                img_path = os.path.join(date_path_img, img_name)

                                txt_name = f'{now_time}_info.txt'
                                txt_path = os.path.join(date_path_txt, txt_name)

                                TaskWrite = threading.Thread(name='WriteData', target=WriteImgAndTxt, kwargs={"Im": im0, "img_path": img_path, "txt_path": txt_path, "upload_dic": upload_dic, "txt_name": txt_name, "current_folder": date_path_txt})  # å†™æ–‡ä»¶åˆ°æ–‡ä»¶å¤¹
                                TaskWrite.start()

                        # åœ¨UIä¸­ç”»å‡ºæ£€æµ‹æ¡†åŠä¼°è®¡é€Ÿåº¦å€¼

                        # tool_vehicle.draw_boxes_speed(im0, outputs, names)
                        # for c in valid_car_info:
                        #     l=f"#{names[int(c[4])]}:{int(c[5])}km/h"
                        #     t_size = cv2.getTextSize(l, cv2.FONT_HERSHEY_PLAIN, 2, 2)[0]
                        #     x1=int(c[0])
                        #     y1=int(c[1])
                        #     x2=int(c[2])
                        #     y2=int(c[3])

                        #     cv2.rectangle(im0, (x1, y1), (x2, y2), [0,0, 255], 3)  # ç”»å‡ºè½¦å‹çš„é¢„æµ‹æ¡†
                        #     cv2.line(im0,(812, 189),(1075, 188),[0,0,0],3)
                        #     cv2.line(im0,(1075, 188),(968, 684),[0,0,0],3)
                        #     cv2.line(im0,(968, 684),(43, 676),[0,0,0],3)
                        #     cv2.line(im0,(43, 676),(812, 189),[0,0,0],3)
                        #     cv2.circle(im0, (x2, y2), radius=4, color=(0, 0, 255), thickness=5)  # å°†é¢„æµ‹æ¡†å³ä¸‹è§’æ ‡å‡ºæ¥
                        #     cv2.rectangle(im0, (x1, y1), (x1 + t_size[0] + 3, y1 + t_size[1] + 4), [0,0, 255], -1)  # ç”»å‡ºæ ‡ç­¾çš„èƒŒæ™¯æ¡†
                        #     cv2.putText(im0, l, (x1, y1 + t_size[1] + 4), cv2.FONT_HERSHEY_PLAIN, 2, [255, 255, 255], 2)  # å†™å‡ºæ ‡ç­¾
                # if True:

                # video_savev2(vid_cap=vid_cap,im0=im0)
                # TaskVideo = threading.Thread(name='Video',target=video_savev2, kwargs={"im0":im0,"vid_cap":vid_cap,"save_path":save_path})  # å†™æ–‡ä»¶åˆ°æ–‡ä»¶å¤¹
                # TaskVideo.start()
                # ,"vid_cap":vid_cap,"vid_path":vid_path,
                # video_save(im0,vid_cap,vid_path,save_path,vid_writer)

                # ä¿å­˜å¸¦æœ‰æ£€æµ‹ç»“æœçš„å›¾åƒæˆ–è§†é¢‘
        # è®°å½•æ¨ç†æ—¶é—´
        # LOGGER.info( f"{'' if len(det) else '(no detections),'}{(dt[0].dt)*1E3:.1f}ms,{(dt[1].dt)*1E3:.1f}ms,{(dt[2].dt)*1E3:.1f}ms,{(dt[3].dt)* 1E3:.1f}ms")  # å•æ¬¡å…¨éƒ¨æ—¶é—´
        # LOGGER.info(f"{s}{'' if len(det) else '(no detections), '}{dt[1].dt * 1E3:.1f}ms") # Inference Only

    # Print results

    tsum = tuple(x.t * 1E3 for x in dt)  # total speeds
    # DSTime=tsum[3]/deeosortNum
    DSTime = tsum[3] / deeosortNum if deeosortNum != 0 else 0
    t = tuple(x.t / seen * 1E3 for x in dt)  # speeds per image
    LOGGER.info(f'åœ¨æ€»å…±{seen}å¸§å›¾åƒä¸­æ£€æµ‹åˆ°äº†{CarTotal}è¾†è½¦,è·Ÿè¸ªå¤„ç†äº†{deeosortNum}å¸§å›¾åƒå¹¶è¯†åˆ«åˆ°äº†{DataNum}è¾†æœ‰æ•ˆè½¦è¾†')
    LOGGER.info(f'Speed: {t[0]:.1f} ms pre-process, {t[1]:.1f}ms inference, {t[2]:.1f}ms NMS, {DSTime:.1f} ms DeepSort')
    # LOGGER.info(f'æœ‰æ•ˆè¿½è¸ªå¹³å‡å¤„ç†æ—¶é—´ï¼š (%.3fms)/img,{(1, 3, *imgsz)}' % (deepsortTime))
    LOGGER.info('Done. (%.3fs)' % (time.time() - t0))
    cv2.destroyAllWindows()  # å…³é—­çª—å£
    if save_img:
        s = f"\n{len(list(save_dir.glob('labels/*.txt')))} labels saved to {save_dir / 'labels'}" if save_txt else ''
    # LOGGER.info(f"Results saved to {colorstr('bold', save_dir)}{s}")
    # å¦‚æœé€‰æ‹©æ›´æ–°æ¨¡å‹ï¼Œå»é™¤ä¼˜åŒ–å™¨ä»¥å‡å°‘æ¨¡å‹å¤§å°
    if update:
        strip_optimizer(weights[0])  # update model (to fix SourceChangeWarning)

    # run() ç»“æŸå¤„æ·»åŠ 
    stop_run_flag = True
    cv2.destroyAllWindows()
    LOGGER.info("ğŸ“½ï¸ run() è‡ªç„¶ç»“æŸï¼Œè®¾ç½® stop_run_flag = True ä»¥è§¦å‘é‡å¯")
    exit_program()


# è§£æå‘½ä»¤è¡Œå‚æ•°
def parse_opt():
    parser = argparse.ArgumentParser()
    # è·å–å½“å‰æ—¶é—´å¯¹åº”çš„é…ç½®
    current_source, current_weights, current_save_dir = get_current_config()
    parser.add_argument('--weights', nargs='+', type=str, default=current_weights,
                        help='model path or triton URL')
    parser.add_argument('--source', type=str, default=current_source,
                        help='file/dir/URL/glob/screen/0(webcam)')
    # parser.add_argument('--weights', nargs='+', type=str, default='yolov5/weights/best1.engine',
    #                     help='model path or triton URL')
    parser.add_argument('--deep_sort_weights', type=str, default='deep_sort_pytorch/deep_sort/deep/checkpoint/ckpt1.t7',
                        help='ckpt.t7 path')
    # file/folder, 0 for webcam
    # parser.add_argument('--source', type=str, default='rtsp://admin:admin12345@192.168.10.3', help='file/dir/URL/glob/screen/0(webcam)')
    # parser.add_argument('--source', type=str, default='inference/images/test02.avi', help='file/dir/URL/glob/screen/0(webcam)')
    parser.add_argument('--data', type=str, default='yolov5/data/coco128.yaml', help='(optional) dataset.yaml path')
    parser.add_argument('--imgsz', '--img', '--img-size', nargs='+', type=int, default=[640], help='inference size h,w')
    parser.add_argument('--conf-thres', type=float, default=0.25, help='confidence threshold')  # ç›®æ ‡ç½®ä¿¡åº¦ç›®æ ‡ç­›é€‰
    parser.add_argument('--iou-thres', type=float, default=0.45, help='NMS IoU threshold')
    parser.add_argument('--max-det', type=int, default=1000, help='maximum detections per image')
    parser.add_argument('--device', default='0', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')
    # parser.add_argument('--view-img', type=bool, default=True, help='display tracking video results')  # æ˜¾ç¤ºè§†é¢‘
    parser.add_argument('--view-img', action='store_true', help='show results')  # ä¸æ˜¾ç¤ºè§†é¢‘
    # parser.add_argument('--save-txt', action='store_true', help='save MOT compliant results to *.txt')  # ä¸ä¿å­˜è®¡æ•°txtæ–‡ä»¶
    # parser.add_argument('--save-txt', default='True', help='save results to *.txt')  # ä¿å­˜è®¡æ•°txtæ–‡ä»¶
    # parser.add_argument('--save', action='store_true', help='do not save images/videos')  # ä¸ä¿å­˜è¯†åˆ«åçš„å›¾ç‰‡æˆ–è§†é¢‘
    parser.add_argument('--save', type=bool, default=True, help='do not save images/videos')  # ä¿å­˜è¯†åˆ«åçš„å›¾ç‰‡æˆ–è§†é¢‘
    parser.add_argument('--ref-time', type=str, default='2023-01-01 00:00:00', help='%Y-%m-%d %H:%M:%S')
    parser.add_argument('--classes', nargs='+', type=int, help='filter by class: --classes 0, or --classes 0 2 3')
    parser.add_argument('--agnostic-nms', action='store_true', help='class-agnostic NMS')
    parser.add_argument('--augment', action='store_true', help='augmented inference')
    parser.add_argument('--visualize', action='store_true', help='visualize features')
    parser.add_argument('--update', action='store_true', help='update all models')
    parser.add_argument('--project', default=current_save_dir, help='save results to project/name')
    parser.add_argument('--name', default='exp', help='save results to project/name')
    parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok, do not increment')
    parser.add_argument('--half', action='store_true', help='use FP16 half-precision inference')
    parser.add_argument('--dnn', action='store_true', help='use OpenCV DNN for ONNX inference')
    parser.add_argument('--vid-stride', type=int, default=1, help='video frame-rate stride')
    parser.add_argument("--config_deepsort", type=str,
                        default="deep_sort_pytorch/configs/deep_sort.yaml")  # deepsortå‚æ•°è®¾ç½®
    parser.add_argument('--camera-device', type=str, default=device_code1, help='waiting for front enf given')  # todo
    opt = parser.parse_args()  # è§£æå‚æ•°
    opt.imgsz *= 2 if len(opt.imgsz) == 1 else 1  # å¦‚æœåªæœ‰ä¸€ä¸ªå°ºå¯¸ï¼Œæ‰©å±•ä¸ºä¸¤å€
    print_args(vars(opt))  # æ‰“å°å‚æ•°
    return opt


# æ‰§è¡Œåˆ†æåŠŸèƒ½
def analysisFunction(opt):
    check_requirements(exclude=('tensorboard', 'thop'))  # æ£€æŸ¥ç¯å¢ƒè¦æ±‚ï¼Œæ’é™¤tensorboardå’Œthop
    run(**vars(opt))  # è°ƒç”¨runå‡½æ•°æ‰§è¡Œåˆ†æ


def start_run_thread(opt):
    global current_run_thread, stop_run_flag
    stop_run_flag = False
    current_run_thread = threading.Thread(target=analysisFunction,name='MainCode', args=(opt,))
    current_run_thread.start()


# HTTPæœåŠ¡æ¥å£ï¼Œç­‰å¾…å‰ç«¯å‘é€å¼€å§‹æŒ‡ä»¤å¹¶æ‰§è¡Œä¸»ç¨‹åº
app = Flask(__name__)

# å®šä¹‰ä¸€ä¸ªæ¥æ”¶POSTè¯·æ±‚çš„æ¥å£
@app.route('/api/analyze-result', methods=['POST'])
def post_start():
    client_ip = request.remote_addr  # è·å–è¯·æ±‚ç«¯çš„IPåœ°å€
    data = request.json  # è·å–POSTè¯·æ±‚ä¸­çš„æ•°æ®
    if 'deviceCode' not in data or 'videoName' not in data or 'videoStartTime' not in data:
        return jsonify({'error': 'ç¼ºå°‘å¿…è¦çš„å­—æ®µ'}), 400  # è¿”å›é”™è¯¯ä¿¡æ¯

    # åœ¨è¿™é‡Œå¤„ç†æ¥æ”¶åˆ°çš„æ•°æ®
    device_code = data['deviceCode']
    video_name = data['videoName']
    video_start_time = data['videoStartTime']

    # æ‰§è¡Œä¸šåŠ¡é€»è¾‘
    opt = parse_opt()
    opt.source = 'http://' + client_ip + ':' + CLIENT_PORT + '/' + video_name  # è®¾ç½®è§†é¢‘æº
    opt.ref_time = video_start_time  # è®¾ç½®å‚è€ƒæ—¶é—´
    opt.camera_device = device_code  # è®¾ç½®è®¾å¤‡ç¼–ç 

    # å¼€å§‹å¼‚æ­¥æ‰§è¡Œçº¿ç¨‹
    task1 = threading.Thread(target=analysisFunction, args=(opt,))
    task1.start()

    LOGGER.info('..........POST..........')
    return jsonify({'message': 'POSTè¯·æ±‚æˆåŠŸï¼'})

def check_device_status(device_code):
    url1 = f"http://222.219.137.122:19030/api/device/{device_code}"  # åŠ¨æ€æ›¿æ¢{code}ä¸ºå®é™…çš„è®¾å¤‡ç¼–å·
    headers1 = {'Content-Type': 'application/x-www-form-urlencoded'}  # è¯·æ±‚å¤´ä¿¡æ¯
    try:
        # å‘é€ GET è¯·æ±‚
        response = requests.get(url1, headers=headers1)

        # æ£€æŸ¥ HTTP çŠ¶æ€ç 
        if response.status_code == 200:
            # å°è¯•è§£æ JSON å“åº”
            try:
                data = response.json()
                print(f"è®¾å¤‡åœ¨çº¿ï¼Œæ•°æ®: {data}")
                return True, data  # è¿”å›çŠ¶æ€å’Œæ•°æ®
            except ValueError:
                print(f"è®¾å¤‡åœ¨çº¿ï¼Œæ—¶é—´: {response.text}")
                return True, response.text
        else:
            print(f"è¯·æ±‚å¤±è´¥ | è®¾å¤‡: {device_code} | çŠ¶æ€ç : {response.status_code}")
            return False, None
    except Exception as e:
        print(f"è¯·æ±‚å¼‚å¸¸ | è®¾å¤‡: {device_code} | é”™è¯¯: {str(e)}")
        return False, None

def write_time_now(file_path,current_date):
    try:
        with open(file_path, 'a') as file:
            file.write(current_date + '\n')
    except Exception as e:
        print(f"å†™å…¥æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")

import subprocess
def ResetTime():
    """
    è‡ªåŠ¨åŒæ­¥æ—¶é—´å‡½æ•°
    """
    # æŒ‡å®šNTPæœåŠ¡å™¨çš„IPåœ°å€
    ntp_server_ip = "114.118.7.161"
    # æ„å»ºntpdateå‘½ä»¤
    command = ["ntpdate", ntp_server_ip]
    # è°ƒç”¨ntpdateå‘½ä»¤æ¥åŒæ­¥æ—¶é—´
    subprocess.run(command, check=True)
    print(f"ç³»ç»Ÿæ—¶é—´å·²åŒæ­¥åˆ°NTPæœåŠ¡å™¨ {ntp_server_ip}")

def addtime(time_string,AddMinues):
    time_obj = datetime.strptime(time_string, "%Y-%m-%d %H:%M:%S")
    # å¢åŠ 10åˆ†é’Ÿ
    time_obj += timedelta(minutes=AddMinues)
    # å°† datetime å¯¹è±¡è½¬æ¢å›æ—¶é—´å­—ç¬¦ä¸²
    new_time_string = time_obj.strftime("%Y-%m-%d %H:%M:%S")
    return new_time_string

def is_valid_time_format(time_str):
    time_format = "%Y-%m-%d %H:%M:%S"
    try:
        datetime.strptime(time_str,time_format)
        return True
    except ValueError:
        return False
def sync_device_time():
    config = load_config()
    try:
        current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        print(f"[{current_time}] å°è¯•è°ƒç”¨ SetTimeFromDevice.py è„šæœ¬è¿›è¡Œæ—¶é—´åŒæ­¥...")
        result = subprocess.run(
            ["sudo", "-S", "/home/uvi/env/yolov5/bin/python", "/home/uvi/Traffic-Survey-v2.1/SetTimeFromDevice.py"],
            input="uvi123\n",  # âš ï¸ æ³¨æ„æ›¿æ¢ä¸ºä½ çš„å®é™…sudoå¯†ç 
            capture_output=True,
            text=True,
            timeout=30
        )
        print("[SetTimeFromDevice è¾“å‡º]:")
        print(result.stdout)
        if result.stderr:
            print("[é”™è¯¯]:", result.stderr)
        return True
    except Exception as e:
        print(f"[åŒæ­¥å¼‚å¸¸]: {e}; {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        return False

def start_check_device_status():
    device_code2 = device_code1  # è·å–è®¾å¤‡ç¼–å·
    last_sync_minute = -1  # åˆå§‹åŒ–ä¸Šä¸€æ¬¡åŒæ­¥çš„åˆ†é’Ÿå€¼
    TImeHMSNow=datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    time.sleep(90)
    while True:
        time.sleep(25)  # ç¡çœ 25ç§’
        CodeNumber=count_threads_by_name('MainCode')
        if CodeNumber < 3:
            #å¦‚æœæ€»çº¿ç¨‹æ•°å°‘äº3ï¼Œé‚£ä¹ˆè¯´æ˜æœ‰ä¸€ä¸ªçº¿ç¨‹æ²¡æœ‰æ‰§è¡Œï¼Œåˆ™ä»£ç é‡å¯
            print(f'çŠ¶æ€ä¿¡å·çº¿ç¨‹ç›‘æµ‹åˆ°æ€»çº¿ç¨‹æ•°ä¸è¶³ï¼Œåªæœ‰ï¼š{CodeNumber}ï¼Œä»£ç é‡å¯')
            myLib.get_PID_and_Kill.kill_termination_PID()
        current_minute = int(datetime.now().strftime('%M'))  # è·å–å½“å‰åˆ†é’Ÿæ•°
        # current_hour = datetime.now().strftime('%H')  # å¦‚æœéœ€è¦æŒ‰å°æ—¶åˆ¤æ–­ä¹Ÿå¯ä»¥ç”¨

        check_device_status(device_code2)  # æ£€æŸ¥è®¾å¤‡çŠ¶æ€
        if current_minute % 2 == 0 and current_minute != last_sync_minute:
            print(f"Resend Failed Data Now!{TImeHMSNow}")
            resend_failed_files(['inference/output/night', 'inference/output', 'inference/output/daytime'])  # è°ƒç”¨é‡å‘å¤±è´¥æ–‡ä»¶çš„å‡½æ•°
        if current_minute % 20 == 0 and current_minute != last_sync_minute:
            # æ›´æ–°ä¸Šæ¬¡åŒæ­¥åˆ†é’Ÿ
            last_sync_minute = current_minute
            state=sync_device_time()  # è°ƒç”¨æ—¶é—´åŒæ­¥å‡½æ•°
            print(f"sync_device_timeçš„æ—¶é—´åŒæ­¥å®Œæˆï¼Œè¿”å›ä¸º{state}")

def WriteNowTime():
    file_path = 'dateNow.txt'
    TImeHMSNow=datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    now = datetime.now()
    current_minute = now.minute-2#æå‰2åˆ†é’Ÿè®°å½•æ—¶é—´ï¼Œé˜²æ­¢å› å…³æœºå¯¼è‡´çš„è¯»å†™é”™è¯¯
    # åˆ¤æ–­æ˜¯å¦æ˜¯æ—¶é—´æ ¼å¼ï¼Œå¦‚æœæ˜¯æ—¶é—´æ ¼å¼ï¼Œåˆ™è¿›è¡Œæ—¶é—´æ›´æ–°ï¼›å¦‚æœä¸æ˜¯æ—¶é—´æ ¼å¼ï¼Œåˆ™é‡æ–°å†å†™ä¸€è¡Œæ—¶é—´ï¼›
    if current_minute % 3==0:
        try:
            with open(file_path, 'a') as file:
                write_time_now(file_path, TImeHMSNow)
        except Exception as e:
            print(f"æ—¶é—´å†™å…¥å‘ç”Ÿé”™è¯¯ï¼š{e}:{TImeHMSNow}")


def check_device_time_status(start_time):
    TImeHMSNow=datetime.now().strftime('%Y-%m-%d %H:%M:%S')

    # è®°å½•å½“å‰ç³»ç»Ÿæ—¶é—´ï¼Œæ¯é—´éš”10åˆ†é’Ÿè®°å½•ä¸€æ¬¡ï¼Œå¦‚æœå½“å‰ç³»ç»Ÿæ—¶é—´æ¯”ä¸Šæ¬¡æ—¶é—´æ›´æ—©ï¼Œåˆ™ä¸è¿›è¡Œè®°å½•
    # åœ¨ä»£ç æ‰§è¡Œè¿‡ç¨‹ä¸­ï¼Œä¿è¯æ—¶é—´æ›´æ–°ä¸é—´æ–­
    file_path = 'dateNow.txt'
        # Y-%m-%d_%H
    now = datetime.now()
    current_minute = now.minute-2#æå‰2åˆ†é’Ÿè®°å½•æ—¶é—´ï¼Œé˜²æ­¢å› å…³æœºå¯¼è‡´çš„è¯»å†™é”™è¯¯
    if current_minute % 5 == 0:
        current_date = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        last_date = RebootCheckTime.read_last_line_of_file(file_path)

        # åˆ¤æ–­æ˜¯å¦æ˜¯æ—¶é—´æ ¼å¼ï¼Œå¦‚æœæ˜¯æ—¶é—´æ ¼å¼ï¼Œåˆ™è¿›è¡Œæ—¶é—´æ›´æ–°ï¼›å¦‚æœä¸æ˜¯æ—¶é—´æ ¼å¼ï¼Œåˆ™é‡æ–°å†å†™ä¸€è¡Œæ—¶é—´ï¼›
        if not is_valid_time_format(last_date):
            try:
                print(f"è®°å½•å½“å‰æ—¶é—´ï¼š{TImeHMSNow}")
                with open(file_path, 'a') as file:
                    file.write('\n' + current_date + '\n')
            except Exception as e:
                print(f"å†™å…¥æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯ï¼š{e}ï¼›{TImeHMSNow}")

        # å¦‚æœæ˜¯æ—¶é—´æ ¼å¼ï¼Œåˆ™è¿›è¡Œæ—¶é—´åˆ†æå’Œæ›´æ–°ï¼›
        else:
            # è§£ææ—¶é—´å­—ç¬¦ä¸²ä¸º datetime å¯¹è±¡
            time1 = datetime.strptime(current_date, "%Y-%m-%d %H:%M:%S")
            time2 = datetime.strptime(last_date, "%Y-%m-%d %H:%M:%S")
            time_difference = abs((time2 - time1).total_seconds())
            # å¼€å‘æ¿é‡å¯ä¹‹åï¼Œç½‘ç»œè¿˜æ²¡æ¢å¤ï¼Œç³»ç»Ÿæ—¶é—´åœ¨å»çš„æŸä¸ªæ—¶é—´ï¼Œè¿™æ—¶å€™å¯ä»¥ä¸æ–­å°è¯•ç½‘ç»œæ›´æ–°
            # å¦‚æœç½‘ç»œ
            if (time1 < time2)&(time_difference>900):  # å¦‚æœcurrent_dateæ—©äºlast_dateï¼Œåˆ™è¯´æ˜current_dateå‡ºç°äº†é—®é¢˜ï¼Œåº”è¯¥äºˆä»¥æ›´æ–°æ—¶é—´
                print(f"{current_date} æ—©äº {last_date}ï¼Œæ—¶é—´è¯¯å·®åœ¨15åˆ†é’Ÿä»¥ä¸Š;{TImeHMSNow}")
                # å°è¯•è°ƒç”¨æœåŠ¡å™¨è¿›è¡Œæ•°æ®åŒæ­¥ï¼Œå¹¶é‡æ–°å†™æ—¶é—´
                # 10såŒæ­¥ä¸€æ¬¡ï¼ŒæŒç»­åŒæ­¥MaxEpochï¼Œå¦‚æœæ—¶é—´åŒæ­¥æˆåŠŸï¼Œåˆ™å†™å…¥file_path
                # AutoReCheckTime.CheckTimeEpoch(file_path, MaxEpoch=10, ntp_server_ip="114.118.7.163")
                sync_device_time()  # è°ƒç”¨æ—¶é—´åŒæ­¥å‡½æ•°

                    # # å¦‚æœåŒæ­¥å¤±è´¥ï¼Œåˆ™å¯èƒ½æ˜¯æ–­ç½‘äº†ï¼Œå¯ä»¥é€šè¿‡æ—¶é’Ÿå‘¨æœŸæ¥è¿›è¡Œä»£ç æ ¡æ­£
                    # new_last_date = read_last_line_of_file(file_path)
                    # if new_last_date == last_date:  # æ•°æ®æ²¡æ›´æ–°ï¼Œåˆ™è¯æ˜æ˜¯å¤±è´¥çš„ï¼Œåˆ™å¯ä»¥last_dateè®°å½•æ—¶é—´+æ—¶é’Ÿå‘¨æœŸæœ€åæ›´æ–°æ—¶é—´
                    #     end_time = time.perf_counter()  # è·å–å½“å‰æ—¶é’Ÿå‘¨æœŸ
                    #     elapsed_time = end_time - start_time
                    #     AddMinues = elapsed_time / 60
                    #     new_time_string = addtime(current_date, AddMinues)
                    #     write_time_now(file_path, new_time_string)
                    #
                    # start_time = time.perf_counter()  # æ›´æ–°æ—¶é’Ÿå‘¨æœŸ

            elif time1 > time2:  # å¦‚æœcurrent_dateæ™šäºlast_dateï¼Œè¯´æ˜æ—¶é—´å¤§æ¦‚ç‡æ˜¯æ­£å¸¸çš„
                # è®¡ç®—æ—¶é—´å·®
                time_difference = abs((time2 - time1).total_seconds())
                if time_difference < 1800:
                    # å¦‚æœæ—¶é—´å·®åœ¨30åˆ†é’Ÿå†…ï¼Œåˆ™è¯æ˜æ—¶é—´æ˜¯è¿ç»­çš„ï¼Œå¯ä»¥è®°å½•æ•°æ®
                    write_time_now(file_path, current_date)
                    start_time = time.perf_counter()  # è·å–å½“å‰æ—¶é’Ÿå‘¨æœŸ
                    print(f"current_dateæ™šäºlast_dateï¼Œå¹¶åœ¨åŠå°æ—¶ä»¥å†…;{TImeHMSNow}")
                else:  # å¦åˆ™å…ˆåŒæ­¥æ•°æ®
                        # AutoReCheckTime.CheckTimeEpoch(file_path, MaxEpoch=10, ntp_server_ip="114.118.7.161")
                        # ç¡®å®å­˜åœ¨æ—¶é—´åŒæ­¥å‡ºç°é”™è¯¯ï¼Œä½†æ•°æ®é‡æ¯”è¾ƒå°‘ï¼Œå¯ä»¥é€šè¿‡æ—¶é—´åŒæ­¥è¿›è¡Œä¿®æ­£
                        # è¿™é‡Œæ¢ä¸ªipåŒæ­¥æ—¶é—´ï¼Œå¦‚æœåŒæ­¥æ—¶é—´å¤±è´¥ï¼Œåˆ™è¿™äº›æ•°æ®å¯ä»¥èˆå¼ƒ
                    new_last_date = RebootCheckTime.read_last_line_of_file(file_path)  # æ£€æŸ¥æ—¶é—´åŒæ­¥æ˜¯å¦æˆåŠŸï¼Œå¦‚æœæˆåŠŸåˆ™æ›´æ–°æ—¶é’Ÿå‘¨æœŸ
                    if new_last_date != last_date:  # æ•°æ®æ›´æ–°äº†ï¼Œåˆ™é‡æ–°è·å–å½“å‰æ—¶é’Ÿå‘¨æœŸ
                        start_time = time.perf_counter()
                        print(f"current_dateæ™šäºlast_dateï¼Œæ—¶é—´è¯¯å·®åœ¨åŠå°æ—¶ä»¥ä¸Š;{TImeHMSNow}")
            else:
                print(f"current_dateï¼š{current_date} ï¼› last_dateï¼š{last_date};TImeHMSNowï¼š{TImeHMSNow}")
                write_time_now(file_path, current_date)


def read_log(log_file_path):
    # å®šä¹‰å‡½æ•°è¯»å–æ—¥å¿—æ–‡ä»¶ï¼Œè¿”å›å¤±è´¥çš„æ–‡ä»¶åˆ—è¡¨
    failed_files = []  # åˆå§‹åŒ–å¤±è´¥æ–‡ä»¶åˆ—è¡¨
    if os.path.exists(log_file_path):  # æ£€æŸ¥æ—¥å¿—æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        with open(log_file_path, 'r') as log_file:  # æ‰“å¼€æ—¥å¿—æ–‡ä»¶
            failed_files = log_file.read().splitlines()  # æŒ‰è¡Œè¯»å–å¤±è´¥æ–‡ä»¶
    return failed_files  # è¿”å›å¤±è´¥æ–‡ä»¶åˆ—è¡¨

def update_device_code(file_content):
    # å®šä¹‰å‡½æ•°æ›´æ–°è®¾å¤‡ç¼–ç 
    device_code_new = device_code1  # è®¾ç½®æ–°çš„è®¾å¤‡ç¼–ç 
    try:
        data = json.loads(file_content)  # å°è¯•å°†æ–‡ä»¶å†…å®¹è§£æä¸ºJSONæ ¼å¼
        data["deviceCode"] = device_code_new  # æ›´æ–°è®¾å¤‡ç¼–ç 
        return json.dumps(data)  # è¿”å›æ›´æ–°åçš„JSONå­—ç¬¦ä¸²
    except json.JSONDecodeError:
        print("æ— æ³•è§£æ JSON æ ¼å¼ï¼Œè¿”å›åŸå§‹å†…å®¹ã€‚")  # è§£æå¤±è´¥æ—¶è¿”å›åŸå§‹å†…å®¹
        return file_content

def send_file_to_server(file_path):
    # å®šä¹‰å‡½æ•°å‘é€æ–‡ä»¶åˆ°æœåŠ¡å™¨
    headers = {'Content-Type': 'application/json'}  # è®¾ç½®è¯·æ±‚å¤´ä¸ºJSONæ ¼å¼
    try:
        with open(file_path, 'r') as f:  # æ‰“å¼€æŒ‡å®šè·¯å¾„çš„æ–‡ä»¶
            file_content = f.read()  # è¯»å–æ–‡ä»¶å†…å®¹
        # æ›´æ–°è®¾å¤‡ç¼–ç 
        updated_content = update_device_code(file_content)  # æ›´æ–°è®¾å¤‡ç¼–ç 
        # å°è¯•å°† updated_content è§£æä¸º JSON æ ¼å¼
        try:
            upload_dic = json.loads(updated_content)  # å°è¯•å°†æ›´æ–°åçš„å†…å®¹è§£æä¸ºJSON
        except json.JSONDecodeError:
            print(f"æ— æ³•è§£ææ–‡ä»¶ {os.path.basename(file_path)} çš„ JSON æ ¼å¼ã€‚å°†å‘é€åŸå§‹å†…å®¹ã€‚")
            upload_dic = {"file_name": os.path.basename(file_path), "file_content": updated_content}  # å‘é€åŸå§‹å†…å®¹
        print(f"æ­£åœ¨å‘é€æ–‡ä»¶: {os.path.basename(file_path)}")  # æ‰“å°å‘é€çš„æ–‡ä»¶è·¯å¾„
        r_json = requests.post(upload_addr3, headers=headers, data=json.dumps(upload_dic))  # å‘é€POSTè¯·æ±‚
        # æ£€æŸ¥æ˜¯å¦å‘é€æˆåŠŸ
        if r_json.status_code == 200:  # å¦‚æœå“åº”çŠ¶æ€ç ä¸º200ï¼Œè¡¨ç¤ºæˆåŠŸ
            print(f"æ–‡ä»¶å‘é€æˆåŠŸâˆšâˆšâˆšâˆš")
            return True  # è¿”å›æˆåŠŸçŠ¶æ€
        else:  # å¦åˆ™æ‰“å°å¤±è´¥ä¿¡æ¯
            print(f"æ–‡ä»¶å‘é€å¤±è´¥ï¼ŒçŠ¶æ€ç : {r_json.status_code}Ã—Ã—Ã—Ã—")
            print(f"æœåŠ¡å™¨å“åº”: {r_json.text}")  # æ‰“å°æœåŠ¡å™¨å“åº”å†…å®¹
            print(f"æ–‡ä»¶{file_path}æ–‡ä»¶ä¼ è¾“å¤±è´¥æ˜¯éç½‘ç»œé—®é¢˜å¯¼è‡´ï¼Œåç»­ä¸å†é‡ä¼ ")  # æ‰“å°æœåŠ¡å™¨å“åº”å†…å®¹

            return True  # è¿”å›å¤±è´¥çŠ¶æ€ï¼Œé™¤äº†ç½‘ç»œé—®é¢˜ä¹‹å¤–ï¼Œå…¶å®ƒå‘é€å¤±è´¥ä»»åŠ¡å‡ä¸å†è¿›è¡Œå¤„ç†
    except RequestException as e:  # æ•è·ç½‘ç»œè¯·æ±‚å¼‚å¸¸
        print(f"å‘é€æ–‡ä»¶æ—¶ç½‘ç»œè¯·æ±‚å¼‚å¸¸ã€‚ã€‚ã€‚")  # æ‰“å°é”™è¯¯ä¿¡æ¯
        # print(f"å‘é€æ–‡ä»¶æ—¶ç½‘ç»œå‘ç”Ÿé”™è¯¯: {e}Ã—Ã—Ã—Ã—")  # æ‰“å°é”™è¯¯ä¿¡æ¯
        return False  # è¿”å›å¤±è´¥çŠ¶æ€

# æ›´æ–°æ—¥å¿—æ–‡ä»¶ï¼ˆç§»é™¤æˆåŠŸå‘é€çš„æ–‡ä»¶ï¼‰
def update_log(log_file_path, failed_files):
    with open(log_file_path, 'w') as log_file:  # æ‰“å¼€æ—¥å¿—æ–‡ä»¶è¿›è¡Œå†™å…¥
        for file in failed_files:
            log_file.write(f"{file}\n")  # å°†å¤±è´¥çš„æ–‡ä»¶é€è¡Œå†™å…¥æ—¥å¿—æ–‡ä»¶

def resubmitlTxtData():
    # å®šä¹‰å‡½æ•°å®šæœŸé‡å‘æ–‡æœ¬æ•°æ®
    while True:
        resend_failed_files(['inference/output/night', 'inference/output', 'inference/output/daytime'])  # è°ƒç”¨é‡å‘å¤±è´¥æ–‡ä»¶çš„å‡½æ•°
        time.sleep(60)  # æ¯éš”60ç§’è°ƒç”¨ä¸€æ¬¡

def remove_line(fileName,lineToSkip):
    with open(fileName,'r', encoding='utf-8') as read_file:
        lines = read_file.readlines()
    currentLine = 1
    with open(fileName,'w', encoding='utf-8') as write_file:
        for line in lines:
            if currentLine == lineToSkip:
                pass
            else:
                write_file.write(line)
            currentLine += 1

def resend_failed_files(possible_save_dirs):
    error_dir = "inference/error_logger"
    Num=0
    for log_file_name in os.listdir(error_dir):
        if not log_file_name.endswith('.txt'):
            continue

        date_str = log_file_name[:10]  # e.g. 2024-10-19
        log_file_path = os.path.join(error_dir, log_file_name)
        failed_files = read_log(log_file_path)
        line_i = 0
        if len(failed_files)>0:
            print(f"å…±æœ‰{len(failed_files)}è¾†è½¦éœ€è¦æ•°æ®é‡ä¼ ï¼Œè¯·ç­‰å¾…æ•°æ®é‡ä¼ å®Œæˆ...")
        else:
            continue

        for file_name in failed_files:
            line_i += 1
            file_found = False
            

            # ä¾æ¬¡å°è¯•æ¯ä¸ªä¿å­˜è·¯å¾„
            for base_dir in possible_save_dirs:
                candidate_path = os.path.join(base_dir, date_str, "txt", file_name)
                if os.path.exists(candidate_path):
                    print(f"âœ… æ‰¾åˆ°æ–‡ä»¶: {file_name}ï¼Œæ­£åœ¨é‡ä¼ ...")
                    if send_file_to_server(candidate_path):
                        print("é‡ä¼ æˆåŠŸ")
                        Num = Num + 1
                        remove_line(log_file_path, line_i)
                        line_i -= 1
                    else:
                        print(f"é‡ä¼ å¤±è´¥: {file_name}")
                    file_found = True
                    break  # æ‰¾åˆ°å³ç»ˆæ­¢æŸ¥æ‰¾

            if not file_found:
                print(f"æ–‡ä»¶{file_name}åœ¨ä»¥ä¸‹ç›®å½•ä¸­éƒ½æœªæ‰¾åˆ°:")
                remove_line(log_file_path, line_i)
                line_i -= 1
                for base_dir in possible_save_dirs:
                    print(f"  - {os.path.join(base_dir, date_str, 'txt')}")
    if Num>0:
        print(f"å…±{Num}è¾†è½¦é‡å‘å®Œæˆ")

def config_checker(need_restart = False):
    global current_source, current_weights, current_save_dir, model, dataset
    global stop_run_flag, current_run_thread
    start_time = time.perf_counter() #å¼€å§‹è®°å½•æ—¶é—´çš„æ—¶é’Ÿå‘¨æœŸ
    time.sleep(90)
    while True:
        WriteNowTime()
        CodeNumber=count_threads_by_name('MainCode')
        if CodeNumber < 3:
            #å¦‚æœæ€»çº¿ç¨‹æ•°å°‘äº3ï¼Œé‚£ä¹ˆè¯´æ˜æœ‰ä¸€ä¸ªçº¿ç¨‹æ²¡æœ‰æ‰§è¡Œï¼Œåˆ™ä»£ç é‡å¯
            print(f'è§†é¢‘æµçº¿ç¨‹ç›‘æµ‹åˆ°æ€»çº¿ç¨‹æ•°ä¸è¶³ï¼Œåªæœ‰ï¼š{CodeNumber}ï¼Œä»£ç é‡å¯')
            myLib.get_PID_and_Kill.kill_termination_PID()
        
        now = datetime.now()
        current_minute = now.minute-2#æå‰3åˆ†é’Ÿè®°å½•æ—¶é—´ï¼Œé˜²æ­¢å› å…³æœºå¯¼è‡´çš„è¯»å†™é”™è¯¯
        # åˆ¤æ–­æ˜¯å¦æ˜¯æ—¶é—´æ ¼å¼ï¼Œå¦‚æœæ˜¯æ—¶é—´æ ¼å¼ï¼Œåˆ™è¿›è¡Œæ—¶é—´æ›´æ–°ï¼›å¦‚æœä¸æ˜¯æ—¶é—´æ ¼å¼ï¼Œåˆ™é‡æ–°å†å†™ä¸€è¡Œæ—¶é—´ï¼›
        if current_minute % 30==0:
            sync_device_time() #30åˆ†é’Ÿè‡ªåŠ¨åŒæ­¥æ—¶é’Ÿä¸€æ¬¡
        
        check_device_time_status(start_time)
        new_source, new_weights, new_save_dir = get_current_config()
        
        # 1. é…ç½®å˜äº†
        if new_source != current_source or new_weights != current_weights or new_save_dir != current_save_dir:
            print(f"ğŸŒ€ æ£€æµ‹åˆ°é…ç½®å˜åŒ–ï¼Œä» {current_source} åˆ‡æ¢åˆ° {new_source}")
            print(f"æ¨¡å‹ä» {current_weights} åˆ‡æ¢åˆ° {new_weights}")
            print(f"è¾“å‡ºç›®å½•åˆ‡æ¢åˆ° {new_save_dir}")
            print("ğŸŒ€ æ£€æµ‹åˆ°é…ç½®å˜åŒ–ï¼Œå‡†å¤‡é‡å¯")
            need_restart = True

        # 2. run() è‡ªç„¶ç»“æŸæˆ–è¶…æ—¶é€€å‡º
        restart_count = 0
        if stop_run_flag and (not current_run_thread or not current_run_thread.is_alive()):
            print("ğŸ”„ run() å·²ç»“æŸï¼Œå‡†å¤‡é‡å¯")
            restart_count += 1
            if restart_count > 2:
                print("âŒ run() é‡å¯è¶…è¿‡3æ¬¡ä»å¤±è´¥ï¼Œç¨‹åºé€€å‡º")
            need_restart = True

        if need_restart:
            if current_run_thread and current_run_thread.is_alive():
                print("â³ å‘é€é€€å‡ºä¿¡å·ç»™æ—§çº¿ç¨‹...")
                stop_run_flag = True  # â‘  é€šçŸ¥é€€å‡º
                myLib.get_PID_and_Kill.kill_termination_PID()

                '''
                # æ—§ä»£ç ï¼Œæ¨å‡ºçº¿ç¨‹ä¿¡å·ï¼Œä»£ç å­˜åœ¨çš„é—®é¢˜ï¼šåªæ¨å‡ºäº†å½“å‰çº¿ç¨‹ï¼Œæœªæ­£å¼æ¨å‡ºç¨‹åºï¼Œçº¿ç¨‹é‡æ–°å¯åŠ¨ä¸ä¼šé‡æ–°åŠ è½½è§†é¢‘æµ
                print("â³ å‘é€é€€å‡ºä¿¡å·ç»™æ—§çº¿ç¨‹...")
                stop_run_flag = True  # â‘  é€šçŸ¥é€€å‡º
                os._exit(0)  # å¼ºåˆ¶é€€å‡ºæ‰€æœ‰çº¿ç¨‹ï¼Œç«‹å³å…³é—­
                current_run_thread.join()  # â‘¡ ç­‰å¾…é€€å‡º
                print("âœ… æ—§çº¿ç¨‹å·²é€€å‡º")
                '''

            stop_run_flag = False  # â‘¢ é‡ç½®é€€å‡ºæ ‡å¿—ï¼Œå‡†å¤‡å¯åŠ¨æ–°çº¿ç¨‹

            # æ›´æ–°é…ç½®
            opt.source = new_source
            opt.weights = new_weights
            opt.project = new_save_dir
            # ä½¿ç”¨ç°æœ‰ opt é‡å¯ï¼ˆä¸éœ€è¦å˜æ›´ source/weightsï¼‰
            start_run_thread(opt)

            # è®°å½•æœ€æ–°é…ç½®
            current_source, current_weights, current_save_dir = new_source, new_weights, new_save_dir
            print("ğŸš€ çº¿ç¨‹é‡å¯å®Œæˆ")

        time.sleep(50)


def clean_file_keep_last_lines(file_path, keep_lines=100):
    try:
        if not os.path.exists(file_path):
            print(f"{os.path.basename(file_path)} ä¸å­˜åœ¨ï¼Œæ— éœ€æ¸…ç†ã€‚")
            return

        with open(file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()

        if len(lines) > keep_lines:
            lines = lines[-keep_lines:]  # åªä¿ç•™æœ€å keep_lines è¡Œ

            with open(file_path, 'w', encoding='utf-8') as f:
                f.writelines(lines)

            print(f"âœ… {os.path.basename(file_path)} æ¸…ç†å®Œæˆï¼Œåªä¿ç•™æœ€å {keep_lines} è¡Œã€‚")
        else:
            print(f"âœ… {os.path.basename(file_path)} è¡Œæ•°å°‘äº {keep_lines}ï¼Œæ— éœ€æ¸…ç†ã€‚")
    except Exception as e:
        print(f"âš ï¸ æ¸…ç† {os.path.basename(file_path)} å‡ºé”™: {e}")

def count_threads_by_name(target_name='MainCode'):
    count = 0
    for thread in threading.enumerate():
        if thread.name == target_name:
            count += 1
    return count

def delete_errorlog():
    """
    åˆ é™¤ error_dir ä¸­ä¸ºç©ºçš„é”™è¯¯æ—¥å¿—æ–‡ä»¶ã€‚
    """
    error_dir = "inference/error_logger"
    deleted_count = 0
    if not os.path.exists(error_dir):
        print("â— é”™è¯¯æ—¥å¿—ç›®å½•ä¸å­˜åœ¨ï¼Œæ— éœ€åˆ é™¤ç©ºæ—¥å¿—ã€‚")
        return

    for file_name in os.listdir(error_dir):
        file_path = os.path.join(error_dir, file_name)
        if os.path.isfile(file_path) and file_name.endswith(".txt"):
            try:
                if os.path.getsize(file_path) == 0:
                    os.remove(file_path)
                    print(f"ğŸ—‘ï¸ åˆ é™¤ç©ºæ—¥å¿—æ–‡ä»¶: {file_name}")
                    deleted_count += 1
            except Exception as e:
                print(f"âš ï¸ æ— æ³•åˆ é™¤ {file_name}: {e}")

    print(f"âœ… ç©ºæ—¥å¿—æ¸…ç†å®Œæˆï¼Œå…±åˆ é™¤ {deleted_count} ä¸ªæ–‡ä»¶ã€‚")


if __name__ == '__main__':

    global opt
    opt = parse_opt()

    # åªåœ¨ç¨‹åºå¯åŠ¨æ—¶æ¸…ç†ä¸€æ¬¡ dateNow.txt
    file_path = 'dateNow.txt'
    clean_file_keep_last_lines(file_path, keep_lines=300)
    #  ç¨‹åºå¯åŠ¨ä¹‹å‰ï¼Œå…ˆæ ¡æ­£æ—¶é—´
    last_date = RebootCheckTime.read_last_line_of_file(file_path)
    print(f"è¯»å–æ–‡æ¡£{file_path}ä¸­çš„æ—¶é—´ä¸º: {last_date}")
    adjusted_datetime_str = RebootCheckTime.adjust_datetime_string1(last_date,addBiasTime=1)
    print(f"è°ƒæ•´æ—¶é—´ä¸ºï¼š{adjusted_datetime_str}")
    if RebootCheckTime.adjust_Time(adjusted_datetime_str): # å…ˆæ‰‹åŠ¨è°ƒæ•´æ—¶é—´ä¸ºadjusted_datetime_str
         print("æ‰‹åŠ¨æ ¡æ­£æ—¶é—´å®Œæˆï¼")
    
    print("ä»£ç é‡å¯åï¼Œå…ˆå°è¯•é‡ä¼ ä¼ è¾“å¤±è´¥çš„è½¦è¾†")
    resend_failed_files(['inference/output/night', 'inference/output', 'inference/output/daytime'])
    print("ä»£ç é‡å¯åï¼Œå…ˆåˆ é™¤ç©ºçš„erroræ–‡ä»¶")
    delete_errorlog()

    # åˆ é™¤æ–‡ä»¶å¤¹
    base_directory = '/home/uvi/Traffic-Survey-v2.1/inference/output'
    RebootCheckTime.delete_old_folders(base_directory)

    if sync_device_time(): #åè‡ªåŠ¨åŒæ­¥
        print("è‡ªåŠ¨æ ¡æ­£æ—¶é—´å®Œæˆ")


    # åˆå§‹åŒ–å…¨å±€å˜é‡
    current_source, current_weights, current_save_dir = get_current_config()
    start_run_thread(opt)

    # start_check_device_status()
    task2 = threading.Thread(target=start_check_device_status,name='MainCode', args=())  # åˆ›å»ºçº¿ç¨‹æ£€æŸ¥è®¾å¤‡çŠ¶æ€
    task2.start()  # å¯åŠ¨çº¿ç¨‹

    # å¯åŠ¨é…ç½®æ£€æŸ¥çº¿ç¨‹
    checker_thread = threading.Thread(target=config_checker,name='MainCode', daemon=True)
    checker_thread.start()

